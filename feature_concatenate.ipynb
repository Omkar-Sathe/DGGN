{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Omkar Sathe\\Desktop\\gene disease prediction\\DisGeneGraph\\DGGN\\util.py:4: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings  \n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import numpy as np\n",
    "    import random\n",
    "    from util import normalization\n",
    "    import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./data/feature/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9112, 256), (2280, 256))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gd_node2vec = normalization(np.load('data/node2vec and line/gd/X_train_gd_node2vec.npy')) \n",
    "X_train_gd_line = normalization(np.load('X_train_ggdd_line.npy'))      \n",
    "\n",
    "X_train_gd_nl = np.concatenate((X_train_gd_node2vec,X_train_gd_line),axis=1)\n",
    "\n",
    "X_test_gd_node2vec = normalization(np.load('data/node2vec and line/gd/X_test_gd_node2vec.npy'))    \n",
    "X_test_gd_line = normalization(np.load('X_test_ggdd_line.npy')) \n",
    "X_test_gd_nl = np.concatenate((X_test_gd_node2vec,X_test_gd_line),axis=1)\n",
    "\n",
    "X_train_gd_nl = normalization(X_train_gd_nl) \n",
    "X_test_gd_nl = normalization(X_test_gd_nl)\n",
    "X_train_gd_nl.shape, X_test_gd_nl.shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.64423168e-01 -3.75955224e-01 -9.46125090e-01 -1.58960271e+00\n",
      "  3.58948648e-01 -1.08429408e+00 -1.57715416e+00  2.10628793e-01\n",
      " -1.54397511e+00  5.13530254e-01 -6.07463658e-01  6.29468083e-01\n",
      " -4.12082136e-01  2.04661358e-02  1.08168030e+00 -2.01128173e+00\n",
      "  2.38979533e-01 -2.68810928e-01 -5.70668459e-01 -9.87852752e-01\n",
      " -2.71052718e-01 -1.99487877e+00  4.15319562e-01  1.49042678e+00\n",
      "  2.88503468e-01  1.18443573e+00  5.91069281e-01 -1.32209575e+00\n",
      "  1.21775138e+00  2.09176496e-01 -5.70016146e-01 -1.54036880e-01\n",
      "  6.15371801e-02 -3.10096025e-01 -2.23585621e-01  5.86916327e-01\n",
      " -2.13785589e-01 -1.29344165e+00  1.58161134e-01 -1.34159338e+00\n",
      "  6.67421103e-01  9.89665508e-01 -2.57134736e-01  6.41969562e-01\n",
      "  8.08358908e-01 -7.67397165e-01 -1.23623991e+00  3.29446197e-01\n",
      "  2.10864353e+00  5.34721971e-01  9.24534321e-01 -8.76251698e-01\n",
      "  1.44369066e+00  1.39396501e+00 -5.79290628e-01  1.87200642e+00\n",
      " -6.49778187e-01 -1.30236936e+00 -5.18226683e-01  2.29142189e+00\n",
      "  2.75372602e-02 -4.03592765e-01  5.72199941e-01  6.98396266e-01\n",
      "  2.16584608e-01 -9.57418144e-01 -3.98956567e-01  2.67023683e-01\n",
      " -2.06359124e+00  2.28490397e-01  1.03101738e-01  1.33650199e-01\n",
      " -1.02527285e+00  2.60287666e+00  3.70258272e-01  1.38653255e+00\n",
      "  2.56458730e-01  7.37892628e-01  1.46138954e+00 -9.31937248e-02\n",
      "  2.76202947e-01 -1.43951520e-01  2.66509086e-01  9.70801264e-02\n",
      "  6.80505812e-01 -1.32857531e-01  1.72210896e+00 -2.24064253e-02\n",
      " -1.13166571e+00 -6.44672662e-02  1.19012344e+00  2.11154723e+00\n",
      " -1.22024012e+00  2.88057625e-01 -1.16518199e+00  6.33470953e-01\n",
      "  5.77715635e-01  1.24844170e+00 -9.67438161e-01 -5.46635330e-01\n",
      "  3.25173080e-01 -5.72675943e-01  1.64063975e-01  1.42353715e-03\n",
      " -2.92601615e-01 -3.72751653e-01 -1.67682171e-02 -1.46429479e-01\n",
      "  5.66298366e-01 -1.42188704e+00 -1.07417035e+00  1.73674607e+00\n",
      " -2.13373208e+00  1.11493850e+00 -7.96818793e-01 -1.75125569e-01\n",
      "  5.84091961e-01 -3.28151047e-01  1.11677754e+00 -2.23457739e-01\n",
      "  4.33172703e-01  7.43544519e-01  5.90583503e-01  5.57380199e-01\n",
      "  9.65010405e-01 -8.77306044e-01 -1.56057906e+00  1.42413187e+00\n",
      " -3.89039695e-01  9.49146077e-02 -1.03564668e+00 -1.66721288e-02\n",
      " -5.76464355e-01 -1.73769668e-01  2.91396976e-01  2.17163235e-01\n",
      "  6.86020926e-02  4.35278863e-01  4.32192326e-01 -1.42155007e-01\n",
      "  2.07764283e-01  9.02238965e-01 -1.50740647e+00  1.31617159e-01\n",
      " -2.71058172e-01  7.27943897e-01 -8.25754583e-01  2.70869464e-01\n",
      "  2.85749257e-01 -3.60060006e-01  2.84966737e-01  2.47029029e-02\n",
      " -2.07656756e-01 -3.31871986e-01  5.44059277e-01 -6.23826027e-01\n",
      "  6.08904585e-02 -5.83441667e-02 -7.04641819e-01  4.11889762e-01\n",
      " -2.24179745e-01  4.82959360e-01  9.83731300e-02 -1.91300720e-01\n",
      " -6.03224874e-01 -1.22738950e-01  6.31450236e-01  3.78007710e-01\n",
      "  4.20821570e-02 -2.55983341e-02  4.46935773e-01 -4.51829642e-01\n",
      " -7.28860617e-01 -2.57477582e-01  8.88477117e-02 -3.93327534e-01\n",
      "  1.64615691e-01  1.71879187e-01 -2.02732429e-01 -3.78492892e-01\n",
      " -8.40552866e-01  2.77384400e-01  4.14816201e-01 -1.00993365e-01\n",
      "  5.83642662e-01 -2.29145139e-01 -3.78026962e-01 -2.05418050e-01\n",
      " -2.58020192e-01 -1.20909913e-02 -4.11722153e-01  2.91966379e-01\n",
      " -2.35804394e-01  8.19068432e-01  1.39473483e-01  2.33834267e-01\n",
      " -6.98147893e-01  6.78651035e-01 -1.07862580e+00  8.64491165e-01\n",
      "  1.92413852e-01 -1.09451485e+00 -9.38420415e-01 -9.12012219e-01\n",
      " -1.13204622e+00 -9.11976218e-01  5.61095655e-01  5.47752440e-01\n",
      "  1.84583202e-01 -3.06555182e-01  2.84742951e-01 -1.20592809e+00\n",
      "  2.85131902e-01 -1.00890481e+00  6.54241145e-01 -1.76896900e-01\n",
      " -9.78769362e-02  1.36010265e+00 -1.25071096e+00 -4.23228472e-01\n",
      " -1.52991593e+00  1.03754699e+00  6.60679460e-01 -1.20512880e-01\n",
      " -5.28533697e-01 -4.91893291e-01 -5.12175381e-01  3.13113481e-01\n",
      "  3.07855338e-01  6.92736149e-01  7.57494569e-01  6.16334617e-01\n",
      "  8.95782769e-01  2.97596991e-01 -4.97719824e-01 -1.26583710e-01\n",
      " -1.59564126e+00  1.19092786e+00 -3.88315618e-01 -7.66414881e-01\n",
      " -9.27011907e-01  3.09041925e-02 -9.15788021e-03 -7.37280905e-01\n",
      "  1.02433300e+00  5.72530508e-01  9.62921232e-02  4.12438780e-01\n",
      " -2.88566381e-01 -2.42975309e-01 -2.77548075e-01  5.53914189e-01\n",
      " -1.87131941e-01  1.07635033e+00  9.26885664e-01  5.54872453e-01]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_gd_nl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/feature/X_train_gd_nl_new.npy',X_train_gd_nl)\n",
    "np.save('data/feature/X_test_gd_nl_new.npy',X_test_gd_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLD network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9112, 256), (2280, 256))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gld_node2vec = normalization(np.load('X_train_gld_node2vec.npy')) \n",
    "X_train_gld_line = normalization(np.load('X_train_gld_line.npy'))      \n",
    "X_train_gld_nl = np.concatenate((X_train_gld_node2vec,X_train_gld_line),axis=1)\n",
    "\n",
    "X_test_gld_node2vec = normalization(np.load('X_test_gld_node2vec.npy')) \n",
    "X_test_gld_line = normalization(np.load('X_test_gld_line.npy')) \n",
    "X_test_gld_nl = np.concatenate((X_test_gld_node2vec,X_test_gld_line),axis=1)\n",
    "\n",
    "X_train_gld_nl = normalization(X_train_gld_nl)   \n",
    "X_test_gld_nl = normalization(X_test_gld_nl)\n",
    "X_train_gld_nl.shape, X_test_gld_nl.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/feature/X_train_gld_nl.npy',X_train_gld_nl)\n",
    "np.save('data/feature/X_test_gld_nl.npy',X_test_gld_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMD network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Omkar Sathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9112, 256), (2280, 256))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gmd_node2vec = normalization(np.load('X_train_gmd_node2vec.npy'))  \n",
    "X_train_gmd_line = normalization(np.load('X_train_gmd_line.npy'))    \n",
    "X_train_gmd_nl = np.concatenate((X_train_gmd_node2vec,X_train_gmd_line),axis=1)\n",
    "\n",
    "X_test_gmd_node2vec = normalization(np.load('X_test_gmd_node2vec.npy'))       \n",
    "X_test_gmd_line = normalization(np.load('X_test_gmd_line.npy')) \n",
    "X_test_gmd_nl = np.concatenate((X_test_gmd_node2vec,X_test_gmd_line),axis=1)\n",
    "\n",
    "X_train_gmd_nl = normalization(X_train_gmd_nl)    \n",
    "X_test_gmd_nl = normalization(X_test_gmd_nl)\n",
    "X_train_gmd_nl.shape, X_test_gmd_nl.shape       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/feature/X_train_gmd_nl.npy',X_train_gmd_nl)\n",
    "np.save('data/feature/X_test_gmd_nl.npy',X_test_gmd_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
